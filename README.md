# **Walmart All Sellers Scraper**

This Python script gets seller information for Walmart items in a json file {product_id.json}.

## **What the Script Does & How to Use It**

The script takes a Walmart product URL as input and saves a JSON file with all the seller details for that product.  
**To use it:**

1. **Install the necessary library:**  
  ```bash
  pip install curl\_cffi
  ```

3. **Save the script** as get\_offers.py.  
4. **Run it from your terminal**, providing the Walmart product URL as an argument:  
```bash
   python get\_offers.py https://www.walmart.com/ip/LEGO-Marvel-Guardians-of-the-Galaxy-Marvel-Rocket-Baby-Groot-Mini-Action-Figure-8-5/5015311522
   ```

The script will print its progress and, if successful, create a JSON file (e.g., 5015311522.json) in the same directory.

## **How It Works & Libraries Used**

This script operates in two main steps:

1. **Initial Page Load**: It first makes a request to the Walmart product page. This step is crucial for establishing a browsing session and collecting essential cookies, such as userAppVersion, which are dynamically generated by the website.  
2. **GraphQL API Request**: After collecting the necessary session data, the script then sends a second request to Walmart's internal GraphQL API. This API provides the detailed seller information. The collected cookies and a dynamically extracted platform version are used in the headers of this request to make it appear legitimate.

The script uses the following key libraries:

* **asyncio**: Python's built-in library for writing concurrent code, allowing the script to perform network operations efficiently without blocking.  
* **curl\_cffi**: A powerful third-party library that provides a Python interface to curl with advanced features like TLS fingerprint impersonation, which helps in mimicking real browser traffic to avoid detection by anti-bot systems.
